{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评分卡建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信用卡数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入依赖包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LuckyDer' from '/Users/gengbh/code/vscode/Data-Analysis-Notes/评分卡建模/LuckyDer.py'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#载入相关包\n",
    "import os\n",
    "# import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scorecardpy as sc\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import sys\n",
    "pd.set_option('display.unicode.ambiguous_as_wide',True)\n",
    "pd.set_option('display.unicode.east_asian_width',True)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',10000)\n",
    "import statsmodels.api as sm\n",
    "import  LuckyDer as lk \n",
    "from imp import reload\n",
    "reload(lk)\n",
    "from LuckyDer import *\n",
    "# from openpyxl import Workbook\n",
    "# from openpyxl.utils.dataframe import dataframe_to_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv(u'/Users/gengbh/code/vscode/Data-Analysis-Notes/评分卡建模/day08_rankingcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'SeriousDlqin2yrs',\n",
       "       'RevolvingUtilizationOfUnsecuredLines', 'age',\n",
       "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
       "       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
       "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       "       'NumberOfDependents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.202690e+05</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>146076.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066840</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>6.670221e+03</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>0.757222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249746</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>1.438467e+04</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>1.115086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>3.400000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>5.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>8.249000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>3.008750e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     150000.000000                         150000.000000  150000.000000   \n",
       "mean           0.066840                              6.048438      52.295207   \n",
       "std            0.249746                            249.755371      14.771866   \n",
       "min            0.000000                              0.000000       0.000000   \n",
       "25%            0.000000                              0.029867      41.000000   \n",
       "50%            0.000000                              0.154181      52.000000   \n",
       "75%            0.000000                              0.559046      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                         150000.000000  150000.000000   1.202690e+05   \n",
       "mean                               0.421033     353.005076   6.670221e+03   \n",
       "std                                4.192781    2037.818523   1.438467e+04   \n",
       "min                                0.000000       0.000000   0.000000e+00   \n",
       "25%                                0.000000       0.175074   3.400000e+03   \n",
       "50%                                0.000000       0.366508   5.400000e+03   \n",
       "75%                                0.000000       0.868254   8.249000e+03   \n",
       "max                               98.000000  329664.000000   3.008750e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    150000.000000            150000.000000   \n",
       "mean                          8.452760                 0.265973   \n",
       "std                           5.145951                 4.169304   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 150000.000000                         150000.000000   \n",
       "mean                       1.018240                              0.240387   \n",
       "std                        1.129771                              4.155179   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       146076.000000  \n",
       "mean             0.757222  \n",
       "std              1.115086  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                        0.000000\n",
       "RevolvingUtilizationOfUnsecuredLines    0.000000\n",
       "age                                     0.000000\n",
       "NumberOfTime30-59DaysPastDueNotWorse    0.000000\n",
       "DebtRatio                               0.000000\n",
       "MonthlyIncome                           0.198207\n",
       "NumberOfOpenCreditLinesAndLoans         0.000000\n",
       "NumberOfTimes90DaysLate                 0.000000\n",
       "NumberRealEstateLoansOrLines            0.000000\n",
       "NumberOfTime60-89DaysPastDueNotWorse    0.000000\n",
       "NumberOfDependents                      0.026160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isnull().sum()/dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除重复值\n",
    "dat.drop_duplicates(inplace=True)\n",
    "# 缺失值处理 使用均值填充\n",
    "dat[\"NumberOfDependents\"].fillna(int(dat[\"NumberOfDependents\"].mean()),inplace=True)\n",
    "# dat.info()\n",
    "# 恢复索引\n",
    "dat.index = range(dat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_rf(X,y,to_fill):\n",
    "\n",
    "    \"\"\"\n",
    "    使用随机森林填补一个特征的缺失值的函数\n",
    "\n",
    "    参数：\n",
    "    X：要填补的特征矩阵\n",
    "    y：完整的，没有缺失值的标签\n",
    "    to_fill：字符串，要填补的那一列的名称\n",
    "    \"\"\"\n",
    "\n",
    "    #构建我们的新特征矩阵和新标签\n",
    "    df = X.copy()\n",
    "    fill = df.loc[:,to_fill]\n",
    "    df = pd.concat([df.loc[:,df.columns != to_fill],pd.DataFrame(y)],axis=1)\n",
    "\n",
    "    # 找出我们的训练集和测试集\n",
    "    Ytrain = fill[fill.notnull()]\n",
    "    Ytest = fill[fill.isnull()]\n",
    "    Xtrain = df.iloc[Ytrain.index,:]\n",
    "    Xtest = df.iloc[Ytest.index,:]\n",
    "\n",
    "    #用随机森林回归来填补缺失值\n",
    "    from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "    rfr = rfr(n_estimators=100)\n",
    "    rfr = rfr.fit(Xtrain, Ytrain)\n",
    "    Ypredict = rfr.predict(Xtest)\n",
    "\n",
    "    return Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat.iloc[:,1:]\n",
    "y = dat[\"SeriousDlqin2yrs\"]#y = data.iloc[:,0]\n",
    "y_pred = fill_missing_rf(X,y,\"MonthlyIncome\")\n",
    "\n",
    "#注意可以通过以下代码检验数据是否数量相同\n",
    "# y_pred.shape ==  data.loc[data.loc[:,\"MonthlyIncome\"].isnull(),\"MonthlyIncome\"].shape\n",
    "#确认我们的结果合理之后，我们就可以将数据覆盖了a\n",
    "dat.loc[dat.loc[:,\"MonthlyIncome\"].isnull(),\"MonthlyIncome\"] = y_pred\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将处理好的数据存储为csv\n",
    "dat.to_csv('dat.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备至此完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = pd.read_csv('dat.csv')\n",
    "path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练测试集\n",
    "dat_train,dat_test = train_test_split(dat,test_size = 0.3,random_state = 886)\n",
    "# 恢复索引\n",
    "dat_train = train.sort_index()\n",
    "dat_test = test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据量：\n",
      " (104573, 11)\n",
      "测试集数据量：\n",
      " (44818, 11)\n"
     ]
    }
   ],
   "source": [
    "print('训练集数据量：\\n {}'.format(dat_train.shape))\n",
    "print('测试集数据量：\\n {}'.format(dat_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**缺失率&集中度筛选**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 2.1 缺失值集中度筛选\n",
    "def feature_selector(dat,keep_col,nouse_col):\n",
    "    #删除日期变量\n",
    "    drop_col_for_dt = reg(\".+dt\",dat.columns)\n",
    "    dat = dat.drop(drop_col_for_dt,axis = 1)\n",
    "    print(\"删除日期变量：{}\".format(drop_col_for_dt))\n",
    "    print(dat.shape)\n",
    "    \n",
    "    #删除date变量\n",
    "    drop_col_for_date = reg(\".+date\",dat.columns)\n",
    "    dat = dat.drop(drop_col_for_date,axis = 1)\n",
    "    print(\"删除date变量：{}\".format(drop_col_for_date))\n",
    "    print(dat.shape)\n",
    "    \n",
    "    #删除cid 和 cd_cid,无用Y变量\n",
    "    dat = dat.drop([i for i in ['cid'] if i in dat.columns],axis = 1)\n",
    "\n",
    "    ##自定义集中度函数\n",
    "    def group_cnt(x):\n",
    "        try:\n",
    "            res = x.value_counts(normalize =True).sort_values(ascending =  False).tolist()[0]\n",
    "            return res\n",
    "        except:\n",
    "            #print(x.name)\n",
    "            return 0\n",
    "    x = dat.apply(group_cnt)\n",
    "    #删除集中度>95的变量，保留历史购买保险\n",
    "    drop_col_for_focu = [i for i in x[x>=0.95].index.tolist() ]\n",
    "    dat = dat.drop(drop_col_for_focu,axis = 1)\n",
    "    print(\"删除集中度>95的变量，保留历史购买保险：{}\".format(drop_col_for_focu))\n",
    "    print(dat.shape)\n",
    "\n",
    "    #剔除事后变量\n",
    "    drop_col_for_After = [i for i in dat.columns if  i in reg(\"v1.+\",dat.columns) + ['effective','mon','starttime','endtime','starttime_endtime','callcount','refusereason']]\n",
    "    dat = dat.drop(drop_col_for_After,axis = 1)\n",
    "    print(\"剔除事后变量：{}\".format(drop_col_for_After))\n",
    "    print(dat.shape)\n",
    "\n",
    "    #剔除type变量\n",
    "    drop_col_for_type = [i for i in dat.columns if  i in reg(\".+type$\",dat.columns)]\n",
    "    dat = dat.drop(drop_col_for_type,axis = 1)\n",
    "    print(\"剔除type变量：{}\".format(drop_col_for_type))\n",
    "    print(dat.shape)\n",
    "    \n",
    "    #干掉类别变量\n",
    "    drop_col_for_class = [i for i in dat.select_dtypes('object').columns.tolist() if i not in ['age_gender','age_marriage', 'gender_marriage','gender_education', 'marriage_education']]\n",
    "    dat = dat.drop(drop_col_for_class,axis = 1)\n",
    "    print(\"干掉类别变量：{}\".format(drop_col_for_class))\n",
    "    print(dat.shape)\n",
    "    \n",
    "    #剔除缺失率>95的变量，保留保险和信用卡用信率字段\n",
    "    miss_rate = miss(dat[dat.columns[~dat.columns.isin(reg('buy.+|user_rate.+',dat.columns))].tolist()])\n",
    "    drop_col_for_miss = miss_rate[miss_rate.miss_rate >= 0.95].index.tolist()\n",
    "    dat = dat.drop(drop_col_for_miss,axis = 1)\n",
    "    print(\"干掉缺失95变量：{}\".format(drop_col_for_miss))\n",
    "    print(dat.shape)\n",
    "    dropcol_for_dt = pd.DataFrame(drop_col_for_dt,columns = ['drop_col'])\n",
    "    dropcol_for_dt['DropReason'] = 'dt'\n",
    "    dropcol_for_dt['Count'] = len(drop_col_for_dt)\n",
    "\n",
    "    dropcol_for_date = pd.DataFrame(drop_col_for_date,columns = ['drop_col'])\n",
    "    dropcol_for_date['DropReason'] = 'date'\n",
    "    dropcol_for_date['Count'] = len(drop_col_for_date)\n",
    "\n",
    "    dropcol_for_focu = pd.DataFrame(drop_col_for_focu,columns = ['drop_col'])\n",
    "    dropcol_for_focu['DropReason'] = 'focu'\n",
    "    dropcol_for_focu['Count'] = len(drop_col_for_focu)\n",
    "\n",
    "    dropcol_for_After = pd.DataFrame(drop_col_for_After,columns = ['drop_col'])\n",
    "    dropcol_for_After['DropReason'] = 'after'\n",
    "    dropcol_for_After['Count'] = len(drop_col_for_After)\n",
    "\n",
    "    dropcol_for_type = pd.DataFrame(drop_col_for_type,columns = ['drop_col'])\n",
    "    dropcol_for_type['DropReason'] = 'type'\n",
    "    dropcol_for_type['Count'] = len(drop_col_for_type)\n",
    "\n",
    "    dropcol_for_class = pd.DataFrame(drop_col_for_class,columns = ['drop_col'])\n",
    "    dropcol_for_class['DropReason'] = 'class'\n",
    "    dropcol_for_class['Count'] = len(drop_col_for_class)\n",
    "\n",
    "    dropcol_for_miss = pd.DataFrame(drop_col_for_miss,columns = ['drop_col'])\n",
    "    dropcol_for_miss['DropReason'] = 'miss'\n",
    "    dropcol_for_miss['Count'] = len(drop_col_for_miss)\n",
    "    dropcol_reason = pd.concat([dropcol_for_dt,dropcol_for_date,dropcol_for_focu,dropcol_for_After, dropcol_for_type,dropcol_for_class,dropcol_for_miss])\n",
    "    dropcol_reason.to_csv(path + '//dropcol_reason.csv')\n",
    "    return dat,dropcol_reason\n",
    "def cate_trans(dat):\n",
    "    #类别变量转换\n",
    "    #类别转换规则，根据坏账排序\n",
    "    dat = dat.copy()\n",
    "    a,b = cate_var_transform(dat.select_dtypes('object'),dat['flagy'])\n",
    "        #转换结果\n",
    "    c = {}\n",
    "    obj = dat.select_dtypes('object').columns.tolist()\n",
    "    for i in range(0,len(obj),1): #循环类别变量\n",
    "        di = {}\n",
    "        for j in range(0,len(b[i]),1): #循环每行取值\n",
    "            di[b[i]['raw data'][j]] = b[i]['transform data'][j]  #将每行结果转换dict\n",
    "        dat[obj[i]] = dat[obj[i]].replace(di)\n",
    "        c[obj[i]] = di\n",
    "    trans_rule = b\n",
    "    print(trans_rule)\n",
    "    print(c)\n",
    "    return dat,c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除日期变量：[]\n",
      "(149391, 12)\n",
      "删除date变量：[]\n",
      "(149391, 12)\n",
      "删除集中度>95的变量，保留历史购买保险：[]\n",
      "(149391, 12)\n",
      "剔除事后变量：[]\n",
      "(149391, 12)\n",
      "剔除type变量：[]\n",
      "(149391, 12)\n",
      "干掉类别变量：[]\n",
      "(149391, 12)\n",
      "干掉缺失95变量：[]\n",
      "(149391, 12)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'flagy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'flagy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-8b905c6afacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#变量筛选\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropcol_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrans_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcate_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-849e3178449d>\u001b[0m in \u001b[0;36mcate_trans\u001b[0;34m(dat)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m#类别转换规则，根据坏账排序\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcate_var_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flagy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m#转换结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'flagy'"
     ]
    }
   ],
   "source": [
    "#变量筛选\n",
    "dt1,dropcol_reason = feature_selector(dat1)\n",
    "dt1,trans_rule = cate_trans(dt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "[INFO] converting into woe values ...\n",
      "NumberOfTime30-59DaysPastDueNotWorse_woe\n",
      "还剩变量：9\n",
      "NumberOfTime60-89DaysPastDueNotWorse_woe\n",
      "还剩变量：8\n",
      "NumberOfOpenCreditLinesAndLoans_woe\n",
      "还剩变量：7\n",
      "age_woe\n",
      "还剩变量：6\n",
      "NumberOfTimes90DaysLate_woe\n",
      "还剩变量：5\n",
      "NumberOfDependents_woe\n",
      "还剩变量：4\n",
      "MonthlyIncome_woe\n",
      "还剩变量：3\n",
      "NumberRealEstateLoansOrLines_woe\n",
      "还剩变量：2\n",
      "RevolvingUtilizationOfUnsecuredLines_woe\n",
      "还剩变量：1\n",
      "DebtRatio_woe\n",
      "还剩变量：0\n",
      "iv剔除变量：[]\n",
      "(104573, 11)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dropcol_reason' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b40c28f33dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mtrain_woe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_woe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropcol_for_iv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_iv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeature_filter_iv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SeriousDlqin2yrs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mdropcol_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropcol_reason\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropcol_for_iv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mdropcol_reason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'//dropcol_reason.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dropcol_reason' is not defined"
     ]
    }
   ],
   "source": [
    "# #### 2.2  聚类、Lasso、IV筛选\n",
    "#1)IV筛选\n",
    "def feature_filter_iv(train,test,flagy):    \n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    #分箱\n",
    "    bins = sc.woebin(train,y = flagy)\n",
    "   \n",
    "    #woe转换\n",
    "    train_woe  = sc.woebin_ply(train,bins = bins)\n",
    "    test_woe  = sc.woebin_ply(test,bins = bins)\n",
    "\n",
    "    iv_info = iv(train_woe,y = flagy)\n",
    "    \n",
    "    ####################add:模型文档：变量IV#####################\n",
    "    iv_info_f1 = iv_info.sort_values(by = 'info_value',ascending = False)\n",
    "    iv_info_f1['info_value'] = iv_info_f1.info_value.round(4)\n",
    "    iv_info_f1['variable'] = [i.replace(\"_woe\",'') for i in iv_info_f1.variable.tolist()]\n",
    "    ##计算缺失率\n",
    "    tmp = miss(train[iv_info_f1.variable])\n",
    "    iv_info_f1['miss_rate'] = tmp['miss_rate'].tolist()\n",
    "\n",
    "    #数据输出\n",
    "    df_iv = pd.DataFrame(columns = ['number','variable','exp','IV','miss_rate'])\n",
    "    df_iv['number'] = list(range(1,iv_info_f1.shape[0]+1))\n",
    "    df_iv['variable'] = iv_info_f1['variable'].tolist()\n",
    "    df_iv['IV'] = iv_info_f1['info_value'].tolist()\n",
    "    df_iv['miss_rate'] = iv_info_f1['miss_rate'].tolist()\n",
    "    df_iv.to_csv(path + '//df_iv.csv')\n",
    "    \n",
    "    #########################存储删除的变量###################################\n",
    "    drop_col_for_iv = [i for i in iv_info[iv_info.info_value <= 0.02].variable.tolist()]\n",
    "    train_woe = train_woe.drop(drop_col_for_iv,axis = 1)\n",
    "    test_woe = test_woe.drop(drop_col_for_iv,axis = 1)\n",
    "    #dat = dat.drop(drop_col,axis = 1)\n",
    "    print(\"iv剔除变量：{}\".format(drop_col_for_iv))\n",
    "    print(train_woe.shape)\n",
    "    \n",
    "    dropcol_for_iv = pd.DataFrame(drop_col_for_iv,columns = ['drop_col'])\n",
    "    dropcol_for_iv['DropReason'] = 'iv'\n",
    "    dropcol_for_iv['Count'] = len(drop_col_for_iv)\n",
    "    \n",
    "    return train_woe,test_woe,bins,dropcol_for_iv,df_iv\n",
    "\n",
    "train_woe,test_woe,bins,dropcol_for_iv,df_iv= feature_filter_iv(dat_train,dat_test,'SeriousDlqin2yrs')\n",
    "\n",
    "dropcol_reason = pd.concat([dropcol_reason,dropcol_for_iv])\n",
    "dropcol_reason.to_csv(path + '//dropcol_reason.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2）LASSO+聚类筛选\n",
    "def feature_selector_als(train_woe):\n",
    "    train_woe = train_woe.copy()\n",
    "\n",
    "    #删除psi不稳定的变量\n",
    "    #psi_df,drop_psi,keep_psi = psi(train_woe,test_woe,0.2)\n",
    "    #drop_psi\n",
    "    \n",
    "    print(\"#####LASSO 筛选....#####\")\n",
    "    #lasso，逻辑回归中的l1\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    reg_x = train_woe.drop(['flagy'],axis = 1)\n",
    "    reg_y = train_woe['flagy']\n",
    "    from sklearn.linear_model import LogisticRegression# lr的Lasso模型\n",
    "    logis = LogisticRegression(\n",
    "       penalty = 'l1'\n",
    "        ,C = 0.1\n",
    "        ,solver ='liblinear').fit(X =reg_x ,y = reg_y)\n",
    "    #系数\n",
    "    coef = pd.Series(logis.coef_[0], index = reg_x.columns)   \n",
    "    print(\"Lasso picked \" + str(sum(coef > 0)) + \n",
    "          \" variables and eliminated the other \" +  \n",
    "          str(sum(coef <= 0)) + \" variables\")   \n",
    "    print(\"Lasso变量个数:\")\n",
    "    print(np.sum(logis.coef_ > 0))\n",
    "    #最终lasso结果变量\n",
    "    import  matplotlib as plt\n",
    "    imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                         coef.sort_values().tail(10)])\n",
    "    plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.pyplot.title(\"Coefficients in the Lasso Model\")\n",
    "    #最终lasso后的变量\n",
    "    lasso_lst = [i for i in list(coef.index[coef.values>0]) + ['flagy']]\n",
    "    \n",
    "    ###########################add:存储因lasso删除的变量########################\n",
    "    drop_col_for_lasso = list(set(train_woe.columns.tolist())-set(lasso_lst))\n",
    "    \n",
    "    \n",
    "    train_woe = train_woe[lasso_lst]\n",
    "    print(\"lasso变量：{}\".format(lasso_lst))\n",
    "    print(train_woe.shape)\n",
    "    \n",
    "    print(\"##### 聚类筛选..########\")\n",
    "    def varclus(train_woe):\n",
    "        from  varclushi import VarClusHi\n",
    "        #聚类\n",
    "        vc = VarClusHi(train_woe,maxeigval2=1,maxclus=None).varclus()\n",
    "        #计算iv\n",
    "        iv_info = iv(train_woe,y = 'flagy')\n",
    "        #合并\n",
    "        d = pd.merge(left = vc.rsquare,right = iv_info,left_on= 'Variable',right_on='variable')\n",
    "        #每个类寻找那红iv最大的行\n",
    "        d['rw'] = d.groupby(['Cluster'])['info_value'].rank(method='max', ascending=False, na_option='keep', pct=False, axis=0)\n",
    "        return d\n",
    "    vc = varclus(train_woe)\n",
    "    model_list = list(vc[vc.rw < 3].variable) +['flagy']\n",
    "\n",
    "    ###########################add:存储因聚类删除的变量########################\n",
    "    drop_col_for_clus = list(set(train_woe.columns.tolist())-set(model_list))\n",
    "    \n",
    "    train_woe = train_woe[model_list]\n",
    "    print(\"聚类后变量：{}\".format(model_list))\n",
    "    print(train_woe.shape)\n",
    "    \n",
    "    #######汇总所有删除的变量\n",
    "    dropcol_for_lasso = pd.DataFrame(drop_col_for_lasso,columns = ['drop_col'])\n",
    "    dropcol_for_lasso['DropReason'] = 'lasso'\n",
    "    dropcol_for_lasso['Count'] = len(drop_col_for_lasso)\n",
    "\n",
    "    dropcol_for_clus = pd.DataFrame(drop_col_for_clus,columns = ['drop_col'])\n",
    "    dropcol_for_clus['DropReason'] = 'clus'\n",
    "    dropcol_for_clus['Count'] = len(drop_col_for_clus)\n",
    "    \n",
    "    dropcol_reason1 = pd.concat([dropcol_for_lasso,dropcol_for_clus])\n",
    "    return train_woe,vc,dropcol_reason1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_woe,vc,dropcol_reason1 = feature_selector_als(train_woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5330eba8000a87c548a69732a83fac8b9a9cf20d15cfa926158716717f1b7bd4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
